{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvmiakWDcuyf"
      },
      "source": [
        "# Лабораторная работа №2\n",
        "## по предмету \"Системы искусственного интеллекта\"\n",
        "### БВТ2101 Юдин Артём\n",
        "\n",
        "В данной лабораторной работе вы будете работать с набором данных, который содержит информацию о технических характеристиках ноутбуков и их цену.\n",
        "Целью работы является изучение теоретических основ методов машинного обучения.\n",
        "\n",
        "В наборе данных для лабораторной работы содержится абор характеристик  мобильных телефонов, включая мощность аккумулятора, характеристики камеры, поддержку сети, память, размеры экрана и другие атрибуты. Столбец «price_range» классифицирует телефоны по ценовым диапазонам (этот столбец необходимо предсказать)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEZ0T1uwj34v"
      },
      "source": [
        "### Задание 1\n",
        "\n",
        "Выгрузите данные из датасета. Изучите колонки, проверьте наличие пропусков. Постройте матрицу корреляции между признаками и целевой переменной. Сделайте выводы, что показывает эта матрица."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "91NHysjQj26f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (5, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>battery_power</th><th>blue</th><th>clock_speed</th><th>dual_sim</th><th>fc</th><th>four_g</th><th>int_memory</th><th>m_dep</th><th>mobile_wt</th><th>n_cores</th><th>pc</th><th>px_height</th><th>px_width</th><th>ram</th><th>sc_h</th><th>sc_w</th><th>talk_time</th><th>three_g</th><th>touch_screen</th><th>wifi</th><th>price_range</th></tr><tr><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>842</td><td>0</td><td>2.2</td><td>0</td><td>1</td><td>0</td><td>7</td><td>0.6</td><td>188</td><td>2</td><td>2</td><td>20</td><td>756</td><td>2549</td><td>9</td><td>7</td><td>19</td><td>0</td><td>0</td><td>1</td><td>1</td></tr><tr><td>1021</td><td>1</td><td>0.5</td><td>1</td><td>0</td><td>1</td><td>53</td><td>0.7</td><td>136</td><td>3</td><td>6</td><td>905</td><td>1988</td><td>2631</td><td>17</td><td>3</td><td>7</td><td>1</td><td>1</td><td>0</td><td>2</td></tr><tr><td>563</td><td>1</td><td>0.5</td><td>1</td><td>2</td><td>1</td><td>41</td><td>0.9</td><td>145</td><td>5</td><td>6</td><td>1263</td><td>1716</td><td>2603</td><td>11</td><td>2</td><td>9</td><td>1</td><td>1</td><td>0</td><td>2</td></tr><tr><td>615</td><td>1</td><td>2.5</td><td>0</td><td>0</td><td>0</td><td>10</td><td>0.8</td><td>131</td><td>6</td><td>9</td><td>1216</td><td>1786</td><td>2769</td><td>16</td><td>8</td><td>11</td><td>1</td><td>0</td><td>0</td><td>2</td></tr><tr><td>1821</td><td>1</td><td>1.2</td><td>0</td><td>13</td><td>1</td><td>44</td><td>0.6</td><td>141</td><td>2</td><td>14</td><td>1208</td><td>1212</td><td>1411</td><td>8</td><td>2</td><td>15</td><td>1</td><td>1</td><td>0</td><td>1</td></tr></tbody></table></div>"
            ],
            "text/plain": [
              "shape: (5, 21)\n",
              "┌───────────────┬──────┬─────────────┬──────────┬───┬─────────┬──────────────┬──────┬─────────────┐\n",
              "│ battery_power ┆ blue ┆ clock_speed ┆ dual_sim ┆ … ┆ three_g ┆ touch_screen ┆ wifi ┆ price_range │\n",
              "│ ---           ┆ ---  ┆ ---         ┆ ---      ┆   ┆ ---     ┆ ---          ┆ ---  ┆ ---         │\n",
              "│ i64           ┆ i64  ┆ f64         ┆ i64      ┆   ┆ i64     ┆ i64          ┆ i64  ┆ i64         │\n",
              "╞═══════════════╪══════╪═════════════╪══════════╪═══╪═════════╪══════════════╪══════╪═════════════╡\n",
              "│ 842           ┆ 0    ┆ 2.2         ┆ 0        ┆ … ┆ 0       ┆ 0            ┆ 1    ┆ 1           │\n",
              "│ 1021          ┆ 1    ┆ 0.5         ┆ 1        ┆ … ┆ 1       ┆ 1            ┆ 0    ┆ 2           │\n",
              "│ 563           ┆ 1    ┆ 0.5         ┆ 1        ┆ … ┆ 1       ┆ 1            ┆ 0    ┆ 2           │\n",
              "│ 615           ┆ 1    ┆ 2.5         ┆ 0        ┆ … ┆ 1       ┆ 0            ┆ 0    ┆ 2           │\n",
              "│ 1821          ┆ 1    ┆ 1.2         ┆ 0        ┆ … ┆ 1       ┆ 1            ┆ 0    ┆ 1           │\n",
              "└───────────────┴──────┴─────────────┴──────────┴───┴─────────┴──────────────┴──────┴─────────────┘"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import polars as pl\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import typing as tp\n",
        "from math import sqrt\n",
        "\n",
        "\n",
        "df = pl.read_csv(\"../csv/AIS2.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (9, 22)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>battery_power</th><th>blue</th><th>clock_speed</th><th>dual_sim</th><th>fc</th><th>four_g</th><th>int_memory</th><th>m_dep</th><th>mobile_wt</th><th>n_cores</th><th>pc</th><th>px_height</th><th>px_width</th><th>ram</th><th>sc_h</th><th>sc_w</th><th>talk_time</th><th>three_g</th><th>touch_screen</th><th>wifi</th><th>price_range</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>2000.0</td><td>2000.0</td><td>2000.0</td><td>2000.0</td><td>2000.0</td><td>2000.0</td><td>2000.0</td><td>2000.0</td><td>2000.0</td><td>2000.0</td><td>2000.0</td><td>2000.0</td><td>2000.0</td><td>2000.0</td><td>2000.0</td><td>2000.0</td><td>2000.0</td><td>2000.0</td><td>2000.0</td><td>2000.0</td><td>2000.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>1238.5185</td><td>0.495</td><td>1.52225</td><td>0.5095</td><td>4.3095</td><td>0.5215</td><td>32.0465</td><td>0.50175</td><td>140.249</td><td>4.5205</td><td>9.9165</td><td>645.108</td><td>1251.5155</td><td>2124.213</td><td>12.3065</td><td>5.767</td><td>11.011</td><td>0.7615</td><td>0.503</td><td>0.507</td><td>1.5</td></tr><tr><td>&quot;std&quot;</td><td>439.418206</td><td>0.5001</td><td>0.816004</td><td>0.500035</td><td>4.341444</td><td>0.499662</td><td>18.145715</td><td>0.288416</td><td>35.399655</td><td>2.287837</td><td>6.064315</td><td>443.780811</td><td>432.199447</td><td>1084.732044</td><td>4.213245</td><td>4.356398</td><td>5.463955</td><td>0.426273</td><td>0.500116</td><td>0.500076</td><td>1.118314</td></tr><tr><td>&quot;min&quot;</td><td>501.0</td><td>0.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>0.1</td><td>80.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>500.0</td><td>256.0</td><td>5.0</td><td>0.0</td><td>2.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;25%&quot;</td><td>852.0</td><td>0.0</td><td>0.7</td><td>0.0</td><td>1.0</td><td>0.0</td><td>16.0</td><td>0.2</td><td>109.0</td><td>3.0</td><td>5.0</td><td>283.0</td><td>875.0</td><td>1208.0</td><td>9.0</td><td>2.0</td><td>6.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><td>&quot;50%&quot;</td><td>1227.0</td><td>0.0</td><td>1.5</td><td>1.0</td><td>3.0</td><td>1.0</td><td>32.0</td><td>0.5</td><td>141.0</td><td>4.0</td><td>10.0</td><td>564.0</td><td>1247.0</td><td>2147.0</td><td>12.0</td><td>5.0</td><td>11.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>2.0</td></tr><tr><td>&quot;75%&quot;</td><td>1615.0</td><td>1.0</td><td>2.2</td><td>1.0</td><td>7.0</td><td>1.0</td><td>48.0</td><td>0.8</td><td>170.0</td><td>7.0</td><td>15.0</td><td>947.0</td><td>1633.0</td><td>3064.0</td><td>16.0</td><td>9.0</td><td>16.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>2.0</td></tr><tr><td>&quot;max&quot;</td><td>1998.0</td><td>1.0</td><td>3.0</td><td>1.0</td><td>19.0</td><td>1.0</td><td>64.0</td><td>1.0</td><td>200.0</td><td>8.0</td><td>20.0</td><td>1960.0</td><td>1998.0</td><td>3998.0</td><td>19.0</td><td>18.0</td><td>20.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>3.0</td></tr></tbody></table></div>"
            ],
            "text/plain": [
              "shape: (9, 22)\n",
              "┌────────────┬────────────┬────────┬────────────┬───┬──────────┬────────────┬──────────┬───────────┐\n",
              "│ statistic  ┆ battery_po ┆ blue   ┆ clock_spee ┆ … ┆ three_g  ┆ touch_scre ┆ wifi     ┆ price_ran │\n",
              "│ ---        ┆ wer        ┆ ---    ┆ d          ┆   ┆ ---      ┆ en         ┆ ---      ┆ ge        │\n",
              "│ str        ┆ ---        ┆ f64    ┆ ---        ┆   ┆ f64      ┆ ---        ┆ f64      ┆ ---       │\n",
              "│            ┆ f64        ┆        ┆ f64        ┆   ┆          ┆ f64        ┆          ┆ f64       │\n",
              "╞════════════╪════════════╪════════╪════════════╪═══╪══════════╪════════════╪══════════╪═══════════╡\n",
              "│ count      ┆ 2000.0     ┆ 2000.0 ┆ 2000.0     ┆ … ┆ 2000.0   ┆ 2000.0     ┆ 2000.0   ┆ 2000.0    │\n",
              "│ null_count ┆ 0.0        ┆ 0.0    ┆ 0.0        ┆ … ┆ 0.0      ┆ 0.0        ┆ 0.0      ┆ 0.0       │\n",
              "│ mean       ┆ 1238.5185  ┆ 0.495  ┆ 1.52225    ┆ … ┆ 0.7615   ┆ 0.503      ┆ 0.507    ┆ 1.5       │\n",
              "│ std        ┆ 439.418206 ┆ 0.5001 ┆ 0.816004   ┆ … ┆ 0.426273 ┆ 0.500116   ┆ 0.500076 ┆ 1.118314  │\n",
              "│ min        ┆ 501.0      ┆ 0.0    ┆ 0.5        ┆ … ┆ 0.0      ┆ 0.0        ┆ 0.0      ┆ 0.0       │\n",
              "│ 25%        ┆ 852.0      ┆ 0.0    ┆ 0.7        ┆ … ┆ 1.0      ┆ 0.0        ┆ 0.0      ┆ 1.0       │\n",
              "│ 50%        ┆ 1227.0     ┆ 0.0    ┆ 1.5        ┆ … ┆ 1.0      ┆ 1.0        ┆ 1.0      ┆ 2.0       │\n",
              "│ 75%        ┆ 1615.0     ┆ 1.0    ┆ 2.2        ┆ … ┆ 1.0      ┆ 1.0        ┆ 1.0      ┆ 2.0       │\n",
              "│ max        ┆ 1998.0     ┆ 1.0    ┆ 3.0        ┆ … ┆ 1.0      ┆ 1.0        ┆ 1.0      ┆ 3.0       │\n",
              "└────────────┴────────────┴────────┴────────────┴───┴──────────┴────────────┴──────────┴───────────┘"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.barplot(x=np.array([0, 1, 2, 3]), \n",
        "            y=df['price_range'].value_counts()[\"count\"], \n",
        "            hue=np.array([0, 1, 2, 3]),\n",
        "            palette=\"muted\")\n",
        "plt.xlabel(\"class\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = df.drop(\"price_range\").to_numpy()\n",
        "y = df['price_range'].to_numpy()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                                    y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42,\n",
        "                                                    shuffle=True)\n",
        "\n",
        "scaler_mm = MinMaxScaler()\n",
        "scaler_std = StandardScaler()\n",
        "X_train_mm = scaler_mm.fit_transform(X_train)\n",
        "X_test_mm = scaler_mm.transform(X_test)\n",
        "\n",
        "X_train_std = scaler_std.fit_transform(X_train)\n",
        "X_test_std = scaler_std.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BaseML:\n",
        "    \"\"\"Base class for score computing\n",
        "    \n",
        "    Args:\n",
        "        - X_test (np.ndarray) - matrix of features\n",
        "        - y_test (np.ndarray) - Ground-Truth labels\n",
        "        - num_neighbours (int) - num neighbours for KNN. Default: None\"\"\"\n",
        "    def score(self, \n",
        "              X_test: np.ndarray, \n",
        "              y_test: np.ndarray, \n",
        "              num_neighbours: tp.Optional[int] = None) -> np.float64:\n",
        "        \"\"\"Computes accuracy score\"\"\"\n",
        "        if num_neighbours is None:\n",
        "            return sum(self.predict(X_test) == y_test) / y_test.shape[0]\n",
        "        return sum(self.predict(X_test, num_neighbours) == y_test) / y_test.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgqsngyck7xl"
      },
      "source": [
        "### Задание 2\n",
        "\n",
        "Реализуйте с нуля алгоритм логистической регрессии для многоклассовой классификации."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$$ \\sigma(z)_i = \\frac{e^{z_i}}{\\sum_{j=1}^K e^{z_j}} $$\n",
        "\n",
        "$$ \\frac{\\partial L}{\\partial w} = X^T (p - y) + 2\\beta w $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ch5WytHwlGpd"
      },
      "outputs": [],
      "source": [
        "class LogisticRegression(BaseML):\n",
        "    \"\"\"Logistic Regression class with L2 penalty\n",
        "\n",
        "    Args:\n",
        "        - l2_coeff (float) - l2 penalty coeff. When equals 0 - no penalty\n",
        "    \n",
        "    Example:\n",
        "    >>> np.random.seed(42)\n",
        "    >>> log_reg = LogisticRegression(0.01)\n",
        "    >>> log_reg.fit(X_train, y_train, batch_size=10, epochs=1, lr=1e-1)\n",
        "    >>> log_reg.score(X_test, y_test)\n",
        "    np.float64(0.645)\n",
        "    \"\"\"\n",
        "    def __init__(self, l2_coeff: float) -> None:\n",
        "        self.l2_coeff = l2_coeff\n",
        "        self.w = None\n",
        "        self.losses = []\n",
        "\n",
        "\n",
        "    def fit(self,\n",
        "            X_train: tp.Union[np.ndarray, list[tp.Union[int, float]]],\n",
        "            y_train: tp.Union[np.ndarray, list[int]],\n",
        "            batch_size: int = 12,\n",
        "            epochs: int = 10,\n",
        "            lr: float = 1e-3) -> list[float]:\n",
        "        \n",
        "        \"\"\"Train function for LogisticRegression class\n",
        "\n",
        "        Args:\n",
        "            - X_train (np.ndarray) - train features\n",
        "            - y_train (np.ndarray) - train labels\n",
        "            - batch_size (int) - num samples in batch\n",
        "            - epochs (int) - num of train epochs\n",
        "            - lr (float) - learning rate coeff\n",
        "        \"\"\"\n",
        "        X_train = np.array(X_train)\n",
        "        y_train = np.array(y_train)\n",
        "        assert X_train.shape[0] == y_train.shape[0], \\\n",
        "            f\"Features and classes must have same number of samples, but {X_train.shape[0]} and {y_train.shape[0]} were given\"\n",
        "        \n",
        "        num_classes = len(np.unique(y_train))\n",
        "        y_train = self.one_hot(y_train, num_classes)\n",
        "\n",
        "        if self.w is None:\n",
        "            self.w = np.random.random((X_train.shape[1], num_classes))\n",
        "        \n",
        "        for epoch in range(epochs):\n",
        "            for X_batch, y_batch in self.batch(X_train, y_train, batch_size):\n",
        "                probs = self.predict_proba(X_batch)\n",
        "                self.losses.append(self.loss(y_batch, probs))\n",
        "\n",
        "                grads = self.get_grad(X_batch, y_batch, probs)\n",
        "                self.w -= grads * lr / np.sqrt(epoch+1)\n",
        "\n",
        "            print(f\"Epoch: {epoch},\\tCE-Loss: \", self.losses[-1])\n",
        "\n",
        "\n",
        "    def loss(self, y_batched: np.ndarray, preds: np.ndarray) -> np.float64:\n",
        "        \"\"\"Cross-Entropy Loss compute\n",
        "        \n",
        "        Args:\n",
        "            - y_batched (np.ndarray) - Grond-Truth labels\n",
        "            - preds (np.ndarray) - predicted labels\"\"\"\n",
        "        return -np.mean(y_batched * np.log(preds))\n",
        "    \n",
        "\n",
        "    def predict_proba(self, X_batched: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Computes probabilities of the classes\n",
        "        \n",
        "        Args:\n",
        "            - X_batched (np.ndarray) - features for predictions\"\"\"\n",
        "        return self.softmax(self.logits(X_batched))\n",
        "    \n",
        "\n",
        "    def predict(self, X_test: np.ndarray) -> np.int64:\n",
        "        \"\"\"Computes predicted class\"\"\"\n",
        "        return np.argmax(self.predict_proba(X_test), axis=1)\n",
        "\n",
        "\n",
        "    def get_grad(self, \n",
        "                 X_batched: np.ndarray, \n",
        "                 y_batched: np.ndarray, \n",
        "                 preds: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Computes gradients for weights\n",
        "        \n",
        "        Args:\n",
        "            - X_batched (np.ndarray) - features that were used\n",
        "            - y_batched (np.ndarray) - Ground-Truth labels\n",
        "            - preds (np.ndarray) - predicted labels\"\"\"\n",
        "        grad_basic = X_batched.T @ (preds - y_batched)\n",
        "        l2_reg = 2 * self.l2_coeff * self.w\n",
        "        return grad_basic + l2_reg\n",
        "    \n",
        "\n",
        "    def batch(self,\n",
        "              X: np.ndarray, \n",
        "              y: np.ndarray, \n",
        "              batch_size: int) -> tp.Generator[tuple[np.ndarray], None, None]:\n",
        "        \"\"\"Batches X and y with shuffle.\n",
        "        \n",
        "        Args:\n",
        "            - X (np.ndarray) - array of features\n",
        "            - y (np.ndarray) - array of labels\n",
        "            - batch_size (int) - number of samples in one batch\"\"\"\n",
        "        perm = np.random.permutation(X.shape[0])\n",
        "\n",
        "        for batch_ in range(X.shape[0] // batch_size):\n",
        "            yield(\n",
        "                X[perm[batch_*batch_size:(batch_+1)*batch_size]],\n",
        "                y[perm[batch_*batch_size:(batch_+1)*batch_size]],\n",
        "            )\n",
        "\n",
        "\n",
        "    def one_hot(self, y: np.ndarray, num_classes: int) -> np.ndarray:\n",
        "        \"\"\"Creates one-hot encoded matrix for y\n",
        "        \n",
        "        Args:\n",
        "            - y (np.ndarray) - matrix of labels\n",
        "            - num_classes (int) - number of unique classes\"\"\"\n",
        "        y_hot = np.zeros((y.shape[0], num_classes))\n",
        "        y_hot[np.arange(y.size), y] = 1\n",
        "        return y_hot\n",
        "\n",
        "\n",
        "    def logits(self, X_batched: np.ndarray) -> np.ndarray:\n",
        "        return np.dot(X_batched, self.w)\n",
        "\n",
        "\n",
        "    def softmax(self, preds: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Computes softmax for logits\"\"\"\n",
        "        preds = np.log(np.maximum(preds, 1e-9)) # боремся с огромными числами\n",
        "        return np.exp(preds) / np.sum(np.exp(preds))\n",
        "    \n",
        "\n",
        "    def get_weights(self) -> np.ndarray:\n",
        "        \"\"\"Copy weights of the model\"\"\"\n",
        "        return self.w.copy()\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og_HzsA2lHyX"
      },
      "source": [
        "Обучите модель."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nwDuPoSHlKDP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0,\tCE-Loss:  0.6929168831881574\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.645"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.random.seed(42)\n",
        "log_reg = LogisticRegression(0.01)\n",
        "log_reg.fit(X_train_std, y_train, batch_size=10, epochs=1, lr=1e-1)\n",
        "log_reg.score(X_test_std, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.975"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train_std, y_train)\n",
        "log_reg.score(X_test_std, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWc9D163lKPB"
      },
      "source": [
        "### Задание 3\n",
        "\n",
        "Реализуйте с нуля алгоритм Наивный Байес."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$$P(y|x) = \\frac{P(x|y) P(y)}{P(x)}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "LRuuj9PDli5A"
      },
      "outputs": [],
      "source": [
        "class NaiveBayes(BaseML):\n",
        "    \"\"\"Implementation of (Multinominal) Naive Bayes\n",
        "    \n",
        "    Example:\n",
        "    >>> nb = NaiveBayes()\n",
        "    >>> nb.fit(X_train_mm, y_train, 1)\n",
        "    >>> nb.score(X_test_mm, y_test)\n",
        "    np.float64(0.59)\n",
        "    \"\"\"\n",
        "    def fit(self, \n",
        "            X_train: tp.Union[np.ndarray, list[tp.Union[int, float]]],\n",
        "            y_train: tp.Union[np.ndarray, list[int]], \n",
        "            alpha: float) -> None:\n",
        "        \"\"\"Computes probabilities from train sets\n",
        "        \n",
        "        Args:\n",
        "            - X_train (np.ndarray) - matrix of features\n",
        "            - y_train (np.ndarray) - matrix of labels\n",
        "            - alpha (float) - smoothing coefficient\"\"\"\n",
        "        X_train = np.array(X_train)\n",
        "        y_train = np.array(y_train)\n",
        "        assert X_train.shape[0] == y_train.shape[0], \\\n",
        "            f\"Features and classes must have same number of samples, but {X_train.shape[0]} and {y_train.shape[0]} were given\"\n",
        "\n",
        "        self.alpha = alpha\n",
        "        self.y_classes, y_counts = np.unique(y_train, return_counts=True)\n",
        "        self.log_p_y = np.log(y_counts / y_counts.sum())\n",
        "\n",
        "        self.log_p_X = np.zeros((len(self.y_classes), X_train.shape[1]))\n",
        "        for i, c in enumerate(self.y_classes):\n",
        "            p_x_y = X_train[y_train == c]\n",
        "            self.log_p_X[i] = np.log((p_x_y.sum(axis=0) + self.alpha) / (p_x_y.sum() + self.alpha * X_train.shape[1]))\n",
        "\n",
        "        \n",
        "    def predict(self, X_test: np.ndarray) -> np.int64:\n",
        "        \"\"\"Predicts labels with Naive Bayes\"\"\"\n",
        "        p_y_x = self.log_posterior(X_test)\n",
        "        return self.y_classes[np.argmax(p_y_x, axis=1)]\n",
        "    \n",
        "\n",
        "    def predict_proba(self, X_test: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Predicts probabilities with Naive Bayes\"\"\"\n",
        "        p_y_x = self.log_posterior(X_test)\n",
        "        posterior = np.exp(p_y_x - p_y_x.max(axis=1, keepdims=True))\n",
        "        return posterior / posterior.sum(axis=1, keepdims=True)\n",
        "    \n",
        "\n",
        "    def log_posterior(self, X_test: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Computes P(y|x)\"\"\"\n",
        "        return np.dot(X_test, self.log_p_X.T) + self.log_p_y\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5EpvZcvli_8"
      },
      "source": [
        "Обучите модель."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5475"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nb = NaiveBayes()\n",
        "nb.fit(X_train_mm, y_train, 1)\n",
        "nb.score(X_test_mm, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "amg6aqULlovg"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.59"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "nb = MultinomialNB()\n",
        "nb.fit(X_train_mm, y_train)\n",
        "nb.score(X_test_mm, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYFhErkHlmFV"
      },
      "source": [
        "### Задание 4\n",
        "\n",
        "Реализуйте с нуля алгоритм kNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$$Eucledian\\ distance(x_1, x_2) = \\sqrt{\\sum_{i=1}^n(x_i^1-x_i^2)^2}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fUQ70y9Plq9u"
      },
      "outputs": [],
      "source": [
        "class KNN(BaseML):\n",
        "    \"\"\"Implementation of K-Nearest Neighbours\n",
        "    \n",
        "    Example:\n",
        "    >>> knn = KNN()\n",
        "    >>> knn.fit(X_train, y_train)\n",
        "    >>> knn.score(X_test, y_test, 35)\n",
        "    np.float64(0.615)\"\"\"\n",
        "    def fit(self, \n",
        "            X_train: tp.Union[np.ndarray, list[tp.Union[int, float]]],\n",
        "            y_train: tp.Union[np.ndarray, list[int]], ) -> None:\n",
        "        \"\"\"Train KNN\n",
        "        \n",
        "        Args:\n",
        "            - X_train (np.ndarray) - matrix of features\n",
        "            - y_train (np.ndarray) - Ground-Truth labels\n",
        "        \"\"\"\n",
        "        self.X_train = np.array(X_train)\n",
        "        self.y_train = np.array(y_train)\n",
        "        assert self.X_train.shape[0] == self.y_train.shape[0], \\\n",
        "            f\"Features and classes must have same number of samples, but {X_train.shape[0]} and {y_train.shape[0]} were given\"\n",
        "\n",
        "    \n",
        "    def _get_neighbours(self, X_test_i: np.ndarray, num_neighbours: int) -> list[int]:\n",
        "        \"\"\"Computes distances for n-nearest neighbours for X_test_i and X_train \n",
        "        \n",
        "        Args:\n",
        "            - X_test_i (np.ndarray) - vector of features from test set\n",
        "            - num_neighbours (int) - number of neighbours to return\"\"\"\n",
        "        assert self.X_train.shape[0] >= num_neighbours, \\\n",
        "            f\"Can't return {num_neighbours} neighbours with only {self.X_train.shape[0]} actual neighbours\"\n",
        "        distances = [(-1, 1e10)] * self.X_train.shape[0]\n",
        "        \n",
        "        \n",
        "        for i in range(self.X_train.shape[0]):\n",
        "            distances[i] = (self.y_train[i],\n",
        "                            self._eucledian_dist(vec1=self.X_train[i], vec2=X_test_i))\n",
        "        \n",
        "        distances.sort(key=lambda x: x[1])\n",
        "        nearest_neighbours = [distances[i][0] for i in range(num_neighbours)]\n",
        "        return nearest_neighbours\n",
        "    \n",
        "\n",
        "    def predict(self, X_test: np.ndarray, num_neighbours: int) -> np.ndarray:\n",
        "        \"\"\"Predicts labels for KNN\"\"\"\n",
        "        def _compute_probs(X_test_i: np.ndarray) -> np.int64:\n",
        "            \"\"\"Compute probabilities of classes\"\"\"\n",
        "            preds = self._get_neighbours(X_test_i=X_test_i, \n",
        "                                         num_neighbours=num_neighbours)\n",
        "            y_classes, y_counts = np.unique(preds, return_counts=True)\n",
        "            return y_classes[np.argmax(y_counts)]\n",
        "        \n",
        "        return np.apply_along_axis(lambda x: _compute_probs(x), axis=1, arr=X_test)\n",
        "\n",
        "\n",
        "    def _eucledian_dist(self, vec1: np.ndarray, vec2: np.ndarray) -> float:\n",
        "        \"\"\"Computes eucledean distance between 2 vectors:\n",
        "        \n",
        "        Args:\n",
        "            - vec1 (np.ndarray) - first vector\n",
        "            - vec2 (np.ndarray) - second vector\"\"\"\n",
        "        return sqrt(sum((vec1 - vec2)*(vec1 - vec2)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASfoCDdSlrJh"
      },
      "source": [
        "Обучите модель."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "78PA6hmwl-1p"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.615"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "knn = KNN()\n",
        "knn.fit(X_train_std, y_train)\n",
        "knn.score(X_test_std, y_test, 35)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.615"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=35)\n",
        "knn.fit(X_train_std, y_train)\n",
        "knn.score(X_test_std, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssFzfn1Pl4AI"
      },
      "source": [
        "### Задание 5\n",
        "\n",
        "Сделайте выводы о результатах обучения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Наши модели Байеса и KNN по своей точности оказались близки к эталонным (только KNN у нас работает немного дольше нужного). Модель Логистической регрессии оказалась сильно хуже реализации, но при этом всё равно показала точность на уровне 0.6\n",
        "\n",
        "По итогу, если брать только наши модели, то лучше всего справляются Логистическая регрессия и KNN, но последний за счёт постоянного расчёта растояния до каждой точки, работает дольше. Наивный Байес же оказался немного хуже"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
